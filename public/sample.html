<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils/control_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js" crossorigin="anonymous"></script>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@2.0.0/dist/tf.min.js"></script>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>

  <link rel="stylesheet" href = "css/styles.css">

  <!-- <script type="module" src="mediapipe.js"></script> -->

  <script type="module">
      const videoElement = document.getElementsByClassName('input_video')[0];
      const canvasElement = document.getElementsByClassName('output_canvas')[0];
      const canvasCtx = canvasElement.getContext('2d');  
      const labelElement = document.getElementById("label");    

      //////////////////////////////////////////////////////
      function get_angles(a,b,c){
        ang = (Math.atan2(c[1]-b[1], c[0]-b[0]) - Math.atan2(a[1]-b[1], a[0]-b[0])) * (180/Math.PI);
        if(ang<0)
          return 360 + ang;
        else
          return ang;                                                 
      }

      //////////////////////////////////////////////////////
      console.log("Start Load");

      var alphabetLabels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'U', 'V', 'W', 'X', 'Y']
      var model;
      let label = '';

      async function loadModel(){
        const model = await tf.loadLayersModel('model.json')
        return model;
      }

      let loadedModel = loadModel().then((resolve, reject)=>{
        model = resolve;
      }).then(function() {
          console.log("Model: ", model) // logs "foo"
      });




      async function predictModel(input){
        console.log("Input is: ", input.arraySync());
        const predictionArr = await model.predict(input);
        console.log("Prediction Array: ", predictionArr);

        const prediction =  predictionArr.argMax().dataSync()[0];
        console.log("ArgMax: ", prediction);

        return alphabetLabels[prediction];
      }




      //////////////////////////////////////////////////////
      function onResults(results) {

        canvasCtx.save();
        canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
        canvasCtx.drawImage(
            results.image, 0, 0, canvasElement.width, canvasElement.height);

        if (results.multiHandLandmarks) {

          const landmark_list =[];

          for (const landmarks of results.multiHandLandmarks) {

              for(let i=0; i<21; i++){
                const temp = [landmarks[i].x, landmarks[i].y]
                landmark_list.push(temp);
              }

              drawConnectors(canvasCtx, landmarks, HAND_CONNECTIONS,
                            {color: '#00FF00', lineWidth: 5});
              drawLandmarks(canvasCtx, landmarks, {color: '#FF0000', lineWidth: 2});
              
              console.log(tf.tensor([landmark_list]));
              // console.log(model.predict(tf.tensor(landmark_list)));

              let predictionMade = predictModel(tf.tensor([landmark_list])).then((resolve, reject)=>{
                label = resolve;
                labelElement.textContent = label;
                console.log("Promise Output: ", resolve, reject);
              }).then(function() {
                  console.log("Answer: ", label);
              });

          }
        }
        canvasCtx.restore();
      }
      

      const hands = new Hands({locateFile: (file) => {
        return `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`;
      }});


      hands.setOptions({
        maxNumHands: 2,
        modelComplexity: 1,
        minDetectionConfidence: 0.7,
        minTrackingConfidence: 0.7
      });
      hands.onResults(onResults);
      
      const camera = new Camera(videoElement, {
        onFrame: async () => {
          await hands.send({image: videoElement});
        },
        width: 1280,
        height: 720
      });
      camera.start();

  </script>

</head>

<body>
  <h1>Media Pipe Demo</h1>
  <h2 id="label">Label Here</h1>

  <div class="container">
    <video class="input_video"></video>
    <canvas class="output_canvas" width="640px" height="480px"></canvas>
  </div>
</body>
</html>


